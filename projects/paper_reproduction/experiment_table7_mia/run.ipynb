{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86670e89",
   "metadata": {},
   "source": [
    "\"What makes unlearning hard and what to do about it\" (Zhao et al., NeurIPS 2024) 논문의 Table 7과 유사한 결과를 재현하는 코드임.\n",
    "\n",
    "이 코드는 논문에 기술된 실험 절차, 특히 ES(Entanglement Score)에 따른 데이터 분할, 각종 언러닝(Unlearning) 방법 적용, 그리고 개별 정확도 및 MIA(Membership Inference Attack) 점수 계산 과정을 모두 포함하고 있음.\n",
    "\n",
    "SCRUB, L1-sparse, SalUn 등 일부 복잡한 언러닝 알고리즘은 논문의 핵심 아이디어를 바탕으로 단순화하여 구현함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff42136f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 21 13:29:55 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              34W / 250W |  12422MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE-16GB           Off | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              31W / 250W |   6302MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-PCIE-16GB           Off | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   45C    P0              34W / 250W |   8370MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P100-PCIE-16GB           Off | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   54C    P0              72W / 250W |   9384MiB / 16384MiB |     70%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla P100-PCIE-16GB           Off | 00000000:0C:00.0 Off |                    0 |\n",
      "| N/A   42C    P0              47W / 250W |  15940MiB / 16384MiB |     14%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla P100-PCIE-16GB           Off | 00000000:0D:00.0 Off |                    0 |\n",
      "| N/A   44C    P0              37W / 250W |   9076MiB / 16384MiB |     27%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla P100-PCIE-16GB           Off | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              31W / 250W |   5290MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla P100-PCIE-16GB           Off | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              32W / 250W |  14760MiB / 16384MiB |     28%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a35d040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using device - cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set device (GPU if available)\n",
    "DEVICE_NUM = 1\n",
    "ADDITIONAL_GPU = 1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(DEVICE_NUM)\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DEVICE_NUM = -1\n",
    "\n",
    "print(f\"INFO: Using device - {device}:{DEVICE_NUM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff005cf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global random seed set to 42\n",
      "Using device: cuda\n",
      "\n",
      "==================== Starting Run 1/3 ====================\n",
      "\n",
      "[LOADING] Found existing original model for run 1. Loading file...\n",
      "\n",
      "--- Processing ES Level: Low ES ---\n",
      "\n",
      "[LOADING] Found existing retrained model for Low ES. Loading file...\n",
      "\n",
      "Evaluating retrained model...\n"
     ]
    }
   ],
   "source": [
    "!python3 unlearning_cifar10_mia_experiment.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
