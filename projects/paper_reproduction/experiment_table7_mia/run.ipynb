{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86670e89",
   "metadata": {},
   "source": [
    "\"What makes unlearning hard and what to do about it\" (Zhao et al., NeurIPS 2024) 논문의 Table 7과 유사한 결과를 재현하는 코드임.\n",
    "\n",
    "이 코드는 논문에 기술된 실험 절차, 특히 ES(Entanglement Score)에 따른 데이터 분할, 각종 언러닝(Unlearning) 방법 적용, 그리고 개별 정확도 및 MIA(Membership Inference Attack) 점수 계산 과정을 모두 포함하고 있음.\n",
    "\n",
    "SCRUB, L1-sparse, SalUn 등 일부 복잡한 언러닝 알고리즘은 논문의 핵심 아이디어를 바탕으로 단순화하여 구현함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff42136f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 21 10:13:11 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   41C    P0              34W / 250W |  12422MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE-16GB           Off | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   41C    P0              31W / 250W |   6302MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-PCIE-16GB           Off | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   45C    P0              34W / 250W |   8370MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P100-PCIE-16GB           Off | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   53C    P0              92W / 250W |   9384MiB / 16384MiB |     40%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla P100-PCIE-16GB           Off | 00000000:0C:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              37W / 250W |   6978MiB / 16384MiB |     21%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla P100-PCIE-16GB           Off | 00000000:0D:00.0 Off |                    0 |\n",
      "| N/A   43C    P0              54W / 250W |   9076MiB / 16384MiB |     14%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla P100-PCIE-16GB           Off | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   66C    P0             144W / 250W |  12916MiB / 16384MiB |     99%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla P100-PCIE-16GB           Off | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              43W / 250W |  14760MiB / 16384MiB |     14%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a35d040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using device - cuda:4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set device (GPU if available)\n",
    "DEVICE_NUM = 4\n",
    "ADDITIONAL_GPU = 1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(DEVICE_NUM)\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DEVICE_NUM = -1\n",
    "\n",
    "print(f\"INFO: Using device - {device}:{DEVICE_NUM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff005cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
      "100.0%\n",
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "\n",
      "==================== Starting Run 1/3 ====================\n",
      "\n",
      "[TRAINING MODE] Step 1/5: Training original model...\n",
      "    Epoch 1/30 completed in 33.62s\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/Unlearning/table_7/unlearning_cifar10_mia_experiment.py\", line 454, in <module>\n",
      "    main()\n",
      "  File \"/workspace/Unlearning/table_7/unlearning_cifar10_mia_experiment.py\", line 332, in main\n",
      "    train_model(original_model, train_loader, CONFIG['epochs'], CONFIG['lr'])\n",
      "  File \"/workspace/Unlearning/table_7/unlearning_cifar10_mia_experiment.py\", line 58, in train_model\n",
      "    for inputs, targets in train_loader:\n",
      "  File \"/root/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 628, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/root/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 671, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/root/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/root/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/root/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/datasets/cifar.py\", line 118, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/root/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n",
      "    img = t(img)\n",
      "  File \"/root/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 135, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/root/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/transforms/functional.py\", line 163, in to_tensor\n",
      "    img = torch.from_numpy(np.array(pic, mode_to_nptype.get(pic.mode, np.uint8), copy=True))\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 unlearning_cifar10_mia_experiment.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
